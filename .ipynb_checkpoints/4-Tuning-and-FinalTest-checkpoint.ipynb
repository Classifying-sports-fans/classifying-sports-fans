{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b8a6ed",
   "metadata": {},
   "source": [
    "## Final model and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b280132",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning \n",
    "\n",
    "For the AdaBoost model, we tune the hyperparameters `learning_rate` (weight applied to each classifier at each boosting iteration. A higher learning rate increases the contribution of each classifier) and `n_estimtors` (maximum number of estimators used). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5b4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## this is to suppress warnings I was getting in this code. \n",
    "import warnings\n",
    "# Suppress FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63688cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## these are our parameters we want to tune.\n",
    "param_grid = {\"n_estimators\": np.arange(50,750,100),\n",
    "              \"learning_rate\": [0.01, 0.1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad909e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the clean survey training data to tune the model\n",
    "survey_train = pd.read_csv('Data/survey_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a881c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features we are focusing on for our model\n",
    "features = ['S2', 'D4', 'Fan_magnitude']\n",
    "\n",
    "## the outputs we are predicting\n",
    "targets = ['VL1r1','VL1r2','VL1r4','VL1r5','VL1r7',\n",
    "           'VL1r10','VL1r11','VL1r12','VL1r13' ,'VL1r14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c930e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VL1r1\n"
     ]
    }
   ],
   "source": [
    "## initialize our model\n",
    "Ada = AdaBoostClassifier()\n",
    "\n",
    "## dictionary for our hyperparameters\n",
    "VL_dict = {}\n",
    "\n",
    "## for our outputs, we determine the best parameters and store those in a dictionary\n",
    "## to use later.\n",
    "for VL in targets:\n",
    "    print(VL)\n",
    "    search = GridSearchCV(Ada, param_grid, cv=5).fit(survey_train[features], survey_train[VL])\n",
    "    VL_dict[VL] = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12294aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## viewing our dictionary of best parameters for each VL output\n",
    "VL_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c38e32d",
   "metadata": {},
   "source": [
    "### Now, we run the final test on the chosen model\n",
    "\n",
    "With the above best performing hyper parameters, we run the model on the test data. We store the accuracy scores and feature importances for each `VL1r` question in distinct dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "survey_test = pd.read_csv('Data/survey_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc733e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {}\n",
    "ada_importance = {}\n",
    "\n",
    "## reminder of our features and outputs\n",
    "# features = ['S2', 'D4', 'Fan_magnitude']\n",
    "# targets = ['VL1r1','VL1r2','VL1r4','VL1r5','VL1r7',\n",
    "#            'VL1r10','VL1r11','VL1r12','VL1r13' ,'VL1r14']\n",
    "\n",
    "for v in VL_dict.items():\n",
    "    ## initialize the model with the best_params_ found above\n",
    "    Ada = AdaBoostClassifier(**v[1])\n",
    "    \n",
    "    ## fit the model with the training data\n",
    "    Ada.fit(survey_train[features].values, survey_train[v[0]].values)\n",
    "    \n",
    "    ## predict the test data\n",
    "    pred = Ada.predict(survey_test[features].values)\n",
    "    \n",
    "    ## store the accuracy score for the test VL values and predicted values\n",
    "    accuracy[v[0]] = accuracy_score(survey_test[v[0]].values, pred)\n",
    "    \n",
    "    ## store the feature importance for each VL\n",
    "    ada_importance[v[0]] = Ada.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d5955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## viewing our final accuracy scores\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9cd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## viewing the feature importance\n",
    "# features = ['S2', 'D4', 'Fan_magnitude']\n",
    "ada_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d2115a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024_new",
   "language": "python",
   "name": "erdos_may_2024_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
