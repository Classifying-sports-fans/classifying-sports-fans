{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453d0e73",
   "metadata": {},
   "source": [
    "## Cleaning the survey data\n",
    "\n",
    "In cleaning the survey data, we focused on certain questions from the survey that we felt were most important for our research question. So, we first cut the number of columns we have from 550 to about 92. \n",
    "\n",
    "Then, we have to replace some 'NaN' entries with zeros, doing so only if respondents answers at least one question from that question bunch. For example, for questions `S15r1-r11` which are self reported sports obsession, if a respondent answers at least one of those with a value, we turned other 'NaN' values to 0. If the respondent left ALL entries to those questions blank, we dropped that row. This resulted in dropping about 3000 surveys from the data set. \n",
    "\n",
    "Beyond that, we create two new columns based on `S15` and `TEAM6` survey questions by viewing these question responses as a vector and finding the Euclidean norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/nfl_survey_data.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37deb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From the survey data, we see there are 550 columns.\n",
    "## We want to include only the following features for initial\n",
    "## exploration.\n",
    "\n",
    "## these features are mainly demographic features\n",
    "features = ['S1', 'S2', 'D4','D5','D6','Hid_Ethnicity_Buckets','Hid_Age','S12r3','VL2','NFL3','NFL4']\n",
    "\n",
    "## self reported fan obsession\n",
    "S15 = ['S15r' + str(i) for i in range(1,12)]\n",
    "\n",
    "##\n",
    "S13 = ['S13r1','S13r2','S13r3' ,'S13r4']\n",
    "\n",
    "## these are our output variables\n",
    "VL1 = ['VL1r' + str(i) for i in range(1,16)]\n",
    "\n",
    "## \n",
    "VL3 = ['VL3r1','VL3r2','VL3r3','VL3r4','VL3r5','VL3r6']\n",
    "\n",
    "##\n",
    "VL4 =['VL4r1','VL4r2','VL4r3','VL4r4','VL4r5','VL4r6']\n",
    "\n",
    "##\n",
    "TEAM6 = ['TEAM6r' + str(i) for i in range(1,33)]\n",
    "\n",
    "##\n",
    "NFL1 = ['NFL1r' + str(i) for i in range(1,5)]\n",
    "NFL2 = ['NFL2r' + str(i) for i in range(1,6)]\n",
    "\n",
    "## creating one array of features of interest\n",
    "features = features + S15 + S13 + VL1 + VL3 + VL4 + TEAM6 + NFL1 + NFL2\n",
    "\n",
    "## new dataframe with only the features from above\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for the survey responses (target columns), if ALL entries for those questions\n",
    "## are null, we drop that row. If respondents answered at least one question from that \n",
    "## set of questions, we turn null values to '0'. We do this for \n",
    "\n",
    "targets = S15  \n",
    "targ_df = 1*~df[targets].isnull() # finding all null values, negating T/F values, and turning to 0/1's\n",
    "targ_df['sum'] = targ_df.sum(axis = 1) # finding the sum of all rows from the 0/1 df above\n",
    "indices = targ_df.loc[targ_df['sum'] == 0].index #finding those indices for which sum is 0\n",
    "df_clean = df.drop(indices) #dropping those rows with ALL 0 entries. \n",
    "\n",
    "## same process as S15 for below\n",
    "targets = S13\n",
    "targ_df = 1*~df_clean[targets].isnull()\n",
    "targ_df['sum'] = targ_df.sum(axis = 1)\n",
    "indices = targ_df.loc[targ_df['sum'] == 0].index\n",
    "df_clean = df_clean.drop(indices)\n",
    "\n",
    "targets = VL3\n",
    "targ_df = 1*~df_clean[targets].isnull()\n",
    "targ_df['sum'] = targ_df.sum(axis = 1)\n",
    "indices = targ_df.loc[targ_df['sum'] == 0].index\n",
    "df_clean = df_clean.drop(indices)\n",
    "\n",
    "targets = VL4\n",
    "targ_df = 1*~df_clean[targets].isnull()\n",
    "targ_df['sum'] = targ_df.sum(axis = 1)\n",
    "indices = targ_df.loc[targ_df['sum'] == 0].index\n",
    "df_clean = df_clean.drop(indices)\n",
    "\n",
    "targets = TEAM6\n",
    "targ_df = 1*~df_clean[targets].isnull()\n",
    "targ_df['sum'] = targ_df.sum(axis = 1)\n",
    "indices = targ_df.loc[targ_df['sum'] == 0].index\n",
    "df_clean = df_clean.drop(indices)\n",
    "\n",
    "df_clean = df_clean.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating magnitude columns\n",
    "## we take the questions from S15 (S15r1-r11) which ask a respondent to self report\n",
    "## fan obsession. We then form a column of the euclidean norm of the vector of responses\n",
    "## from the S15 questions. \n",
    "\n",
    "col_sum = []\n",
    "for i,col in enumerate(S15):\n",
    "    print('working on column ', col)\n",
    "    ## if we are on S15r1, we square the column \n",
    "    if i == 0:\n",
    "        col_sum = df_clean[col].values**2\n",
    "    ## after the first question, we now sum the squares\n",
    "    else: \n",
    "        col_sum = df_clean[col]**2 + col_sum\n",
    "\n",
    "## we want to form a new dataframe, which is the sum of the squares\n",
    "df_sum = pd.DataFrame(col_sum)\n",
    "\n",
    "## we square root the sum of squares dataframe, giving us the magnitude.\n",
    "df_sum = df_sum.apply(np.sqrt)\n",
    "\n",
    "## taking the magnitude dataframe, which is a single column, we place that\n",
    "## in the clean dataframe under correct column name. \n",
    "df_clean['Fan_magnitude'] = df_sum\n",
    "\n",
    "###### \n",
    "######\n",
    "\n",
    "## we want to reverse the scale for the Team6 questions, where 4 is now the highest value, \n",
    "## and 1 the lowest value. \n",
    "\n",
    "for team in TEAM6:\n",
    "#     print('working on team question:', team)\n",
    "    team_list = df_clean[team].values\n",
    "    new_list = list()\n",
    "    \n",
    "    for i in range(len(team_list)):\n",
    "        if team_list[i] == 4:\n",
    "            new_list.append(1)\n",
    "        if team_list[i] == 3:\n",
    "            new_list.append(2)\n",
    "        if team_list[i] == 2:\n",
    "            new_list.append(3)\n",
    "        if team_list[i] == 1:\n",
    "            new_list.append(4)\n",
    "        if team_list[i] == 0:\n",
    "            new_list.append(0)\n",
    "#     print(team_list[:15])\n",
    "    df5 = pd.DataFrame({'xs':new_list})\n",
    "    df_clean[team] = df5['xs'].values\n",
    "    \n",
    "###### \n",
    "######\n",
    "\n",
    "## this magnitude column is formed similar to what was done above with the S15 questions. \n",
    "\n",
    "col_sum = []\n",
    "for i,col in enumerate(TEAM6):\n",
    "    print('working on column ', col)\n",
    "    if i == 0:\n",
    "        col_sum = df_clean[col].values**2\n",
    "    else: \n",
    "        col_sum = df_clean[col]**2 + col_sum\n",
    "\n",
    "df_sum = pd.DataFrame(col_sum)\n",
    "df_sum = df_sum.apply(np.sqrt)\n",
    "\n",
    "df_clean['Team6_magnitude'] = df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8613b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('sports_survey_clean.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024_new",
   "language": "python",
   "name": "erdos_may_2024_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
