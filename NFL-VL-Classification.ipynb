{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e799c4",
   "metadata": {},
   "source": [
    "## In this notebook, I exlore different models, determining the one of best performance, the tuning the hyper parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f7839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "## this is to suppress warnings I was getting in this code. \n",
    "import warnings\n",
    "# Suppress FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf7661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df = pd.read_csv('survey_data_train.csv')\n",
    "# fan_tt, fan_val = train_test_split(survey_df, \n",
    "#                                       shuffle = True,\n",
    "#                                       random_state = 5555,\n",
    "#                                       test_size = .2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6431e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##we should run stratified kfold splits here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb2e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement = True\n",
    "estimators = 100\n",
    "samples = .25\n",
    "\n",
    "models = {'slc': LogisticRegression(penalty=None, max_iter=300),\n",
    "          'svc': SVC(),\n",
    "          'knn': Pipeline((('scale', StandardScaler()), ('knnc',KNeighborsClassifier()))),\n",
    "        'bagged_lr': BaggingClassifier(LogisticRegression(penalty=None, max_iter=300), bootstrap = replacement, n_estimators = estimators, max_samples = samples),\n",
    "         'ada': AdaBoostClassifier(),\n",
    "        'bagged_svc': BaggingClassifier(SVC(),bootstrap = replacement, n_estimators = estimators, max_samples = samples),\n",
    "         'bagged_knn': BaggingClassifier(KNeighborsClassifier(),bootstrap = replacement, n_estimators = estimators, max_samples = samples),\n",
    "         'gbc': GradientBoostingClassifier(),\n",
    "         'rfc': RandomForestClassifier(),\n",
    "          'etc': ExtraTreesClassifier(),\n",
    "         'xgbc': XGBClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149a1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "660265a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fan_tt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a029eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features we want\n",
    "features = ['S2', 'D4','S12r3','Team6_magnitude', 'Fan_magnitude']\n",
    "#removed VL2, 'D6'\n",
    "targets = ['VL1r1','VL1r2','VL1r4','VL1r5','VL1r7',\n",
    "           'VL1r10','VL1r11','VL1r12','VL1r13' ,'VL1r14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e591df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on value question:  VL1r1\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n",
      "Working on value question:  VL1r2\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n",
      "Working on value question:  VL1r4\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n",
      "Working on value question:  VL1r5\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n",
      "Working on value question:  VL1r7\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n",
      "Working on value question:  VL1r10\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n",
      "Working on value question:  VL1r11\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n",
      "Working on value question:  VL1r12\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n",
      "Working on value question:  VL1r13\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n",
      "Working on value question:  VL1r14\n",
      "Working on model:  slc\n",
      "Working on model:  svc\n",
      "Working on model:  knn\n",
      "Working on model:  bagged_lr\n",
      "Working on model:  ada\n",
      "Working on model:  bagged_svc\n",
      "Working on model:  bagged_knn\n",
      "Working on model:  gbc\n",
      "Working on model:  rfc\n",
      "Working on model:  etc\n",
      "Working on model:  xgbc\n"
     ]
    }
   ],
   "source": [
    "all_accuracy = {}\n",
    "\n",
    "kfold = KFold(n_splits=5, \n",
    "                        shuffle=True, \n",
    "                        random_state=5555)\n",
    "\n",
    "xgbc_importance ={}\n",
    "\n",
    "ada_importance ={}\n",
    "\n",
    "gbc_importance ={}\n",
    "\n",
    "for target in targets:\n",
    "    print('Working on value question: ', target)\n",
    "\n",
    "    accuracy = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print('Working on model: ', name)\n",
    "        accu = np.zeros((1,5))\n",
    "        for i, (train_index, test_index) in enumerate(kfold.split(survey_df)):\n",
    "            fans_tt = survey_df.iloc[train_index]\n",
    "            fans_ho = survey_df.iloc[test_index]\n",
    "    \n",
    "            model.fit(fans_tt[features].values, fans_tt[target].values)\n",
    "        \n",
    "            pred = model.predict(fans_ho[features].values)\n",
    "        \n",
    "            accu[0,i] = accuracy_score(fans_ho[target].values, pred)\n",
    "        \n",
    "        if name == 'xgbc':\n",
    "            xgbc_importance[target] = model.feature_importances_\n",
    "        if name == 'ada':\n",
    "            ada_importance[target] = model.feature_importances_\n",
    "        if name == 'gbc':\n",
    "            gbc_importance[target] = model.feature_importances_\n",
    "        accuracy[name] = accu.mean()\n",
    "    all_accuracy[target] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef133971",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VL1r1': {'slc': 0.6544832646963972,\n",
       "  'svc': 0.6394023090256418,\n",
       "  'knn': 0.6319238555879833,\n",
       "  'bagged_lr': 0.6542419373742859,\n",
       "  'ada': 0.6584647651189929,\n",
       "  'bagged_svc': 0.6367485820654852,\n",
       "  'bagged_knn': 0.6431410989529379,\n",
       "  'gbc': 0.6614804466630219,\n",
       "  'rfc': 0.6442271811003215,\n",
       "  'etc': 0.640970390629948,\n",
       "  'xgbc': 0.6390415920177803},\n",
       " 'VL1r2': {'slc': 0.6403680551056199,\n",
       "  'svc': 0.6350605283867178,\n",
       "  'knn': 0.5993487438239498,\n",
       "  'bagged_lr': 0.6403676911126756,\n",
       "  'ada': 0.646037682005572,\n",
       "  'bagged_svc': 0.6355423822464625,\n",
       "  'bagged_knn': 0.6286642987712325,\n",
       "  'gbc': 0.6431415357444712,\n",
       "  'rfc': 0.6337286782033017,\n",
       "  'etc': 0.6202187160804075,\n",
       "  'xgbc': 0.6182888982879955},\n",
       " 'VL1r4': {'slc': 0.7981661307477216,\n",
       "  'svc': 0.7947881306268758,\n",
       "  'knn': 0.77572727610248,\n",
       "  'bagged_lr': 0.7984073852712438,\n",
       "  'ada': 0.802026567117023,\n",
       "  'bagged_svc': 0.7947881306268758,\n",
       "  'bagged_knn': 0.7958735575869598,\n",
       "  'gbc': 0.798648712593355,\n",
       "  'rfc': 0.7896008671767907,\n",
       "  'etc': 0.789842121700313,\n",
       "  'xgbc': 0.7839302938951832},\n",
       " 'VL1r5': {'slc': 0.6462794461192164,\n",
       "  'svc': 0.6486925009445617,\n",
       "  'knn': 0.6120166446693597,\n",
       "  'bagged_lr': 0.6442282730791546,\n",
       "  'ada': 0.6502603641531013,\n",
       "  'bagged_svc': 0.6471233273614224,\n",
       "  'bagged_knn': 0.6383163724754359,\n",
       "  'gbc': 0.6524318732605687,\n",
       "  'rfc': 0.6334904084219233,\n",
       "  'etc': 0.6262531367091981,\n",
       "  'xgbc': 0.6169627991931004},\n",
       " 'VL1r7': {'slc': 0.599225641410167,\n",
       "  'svc': 0.5965719144500102,\n",
       "  'knn': 0.549884068247221,\n",
       "  'bagged_lr': 0.5991051597455834,\n",
       "  'ada': 0.5997087328459225,\n",
       "  'bagged_svc': 0.5887298320609353,\n",
       "  'bagged_knn': 0.5818549517236159,\n",
       "  'gbc': 0.6063439602286749,\n",
       "  'rfc': 0.5602599783205802,\n",
       "  'etc': 0.5596569876089521,\n",
       "  'xgbc': 0.5648433046773821},\n",
       " 'VL1r10': {'slc': 0.7326558453990927,\n",
       "  'svc': 0.7219188543249276,\n",
       "  'knn': 0.68548541735067,\n",
       "  'bagged_lr': 0.7318113089695869,\n",
       "  'ada': 0.7301238376795305,\n",
       "  'bagged_svc': 0.7180583451570376,\n",
       "  'bagged_knn': 0.7199897645184046,\n",
       "  'gbc': 0.7304854282704585,\n",
       "  'rfc': 0.7156460911161698,\n",
       "  'etc': 0.7088897996801229,\n",
       "  'xgbc': 0.7016502712111429},\n",
       " 'VL1r11': {'slc': 0.7677651488403548,\n",
       "  'svc': 0.7550963744118784,\n",
       "  'knn': 0.7467720741701143,\n",
       "  'bagged_lr': 0.7676445215785936,\n",
       "  'ada': 0.7684884028207998,\n",
       "  'bagged_svc': 0.7522013929281994,\n",
       "  'bagged_knn': 0.765593348538532,\n",
       "  'gbc': 0.7693335216390166,\n",
       "  'rfc': 0.7553391577057671,\n",
       "  'etc': 0.7536504488396997,\n",
       "  'xgbc': 0.7542535123499167},\n",
       " 'VL1r12': {'slc': 0.9186876161592483,\n",
       "  'svc': 0.919049425145943,\n",
       "  'knn': 0.9106047160381843,\n",
       "  'bagged_lr': 0.9189289434813596,\n",
       "  'ada': 0.9179637797900926,\n",
       "  'bagged_svc': 0.919049425145943,\n",
       "  'bagged_knn': 0.9189289434813596,\n",
       "  'gbc': 0.9168782800314199,\n",
       "  'rfc': 0.9168782800314199,\n",
       "  'etc': 0.9161543708636751,\n",
       "  'xgbc': 0.9113286980045178},\n",
       " 'VL1r13': {'slc': 0.7820004033041823,\n",
       "  'svc': 0.7813966118080766,\n",
       "  'knn': 0.7468939390078863,\n",
       "  'bagged_lr': 0.7820004033041824,\n",
       "  'ada': 0.7830854662713217,\n",
       "  'bagged_svc': 0.7813966118080766,\n",
       "  'bagged_knn': 0.7797082669349538,\n",
       "  'gbc': 0.7797078301434206,\n",
       "  'rfc': 0.7661965576459266,\n",
       "  'etc': 0.7600433297200968,\n",
       "  'xgbc': 0.7607676756793745},\n",
       " 'VL1r14': {'slc': 0.8443722686879438,\n",
       "  'svc': 0.8395458678428979,\n",
       "  'knn': 0.8208479870826185,\n",
       "  'bagged_lr': 0.8448548505335772,\n",
       "  'ada': 0.8442515686275938,\n",
       "  'bagged_svc': 0.8395458678428979,\n",
       "  'bagged_knn': 0.8432865505335044,\n",
       "  'gbc': 0.8429242319566879,\n",
       "  'rfc': 0.8356863778552516,\n",
       "  'etc': 0.836289150171113,\n",
       "  'xgbc': 0.8286881767083827}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print('Average Accuracy_score for VL1r1')\n",
    "all_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8001f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For question  VL1r1\n",
      "here are the accuracy scores\n",
      "{'slc': 0.6544832646963972, 'svc': 0.6394023090256418, 'knn': 0.6319238555879833, 'bagged_lr': 0.6542419373742859, 'ada': 0.6584647651189929, 'bagged_svc': 0.6367485820654852, 'bagged_knn': 0.6431410989529379, 'gbc': 0.6614804466630219, 'rfc': 0.6442271811003215, 'etc': 0.640970390629948, 'xgbc': 0.6390415920177803}\n",
      "------\n",
      "For question  VL1r2\n",
      "here are the accuracy scores\n",
      "{'slc': 0.6403680551056199, 'svc': 0.6350605283867178, 'knn': 0.5993487438239498, 'bagged_lr': 0.6403676911126756, 'ada': 0.646037682005572, 'bagged_svc': 0.6355423822464625, 'bagged_knn': 0.6286642987712325, 'gbc': 0.6431415357444712, 'rfc': 0.6337286782033017, 'etc': 0.6202187160804075, 'xgbc': 0.6182888982879955}\n",
      "------\n",
      "For question  VL1r4\n",
      "here are the accuracy scores\n",
      "{'slc': 0.7981661307477216, 'svc': 0.7947881306268758, 'knn': 0.77572727610248, 'bagged_lr': 0.7984073852712438, 'ada': 0.802026567117023, 'bagged_svc': 0.7947881306268758, 'bagged_knn': 0.7958735575869598, 'gbc': 0.798648712593355, 'rfc': 0.7896008671767907, 'etc': 0.789842121700313, 'xgbc': 0.7839302938951832}\n",
      "------\n",
      "For question  VL1r5\n",
      "here are the accuracy scores\n",
      "{'slc': 0.6462794461192164, 'svc': 0.6486925009445617, 'knn': 0.6120166446693597, 'bagged_lr': 0.6442282730791546, 'ada': 0.6502603641531013, 'bagged_svc': 0.6471233273614224, 'bagged_knn': 0.6383163724754359, 'gbc': 0.6524318732605687, 'rfc': 0.6334904084219233, 'etc': 0.6262531367091981, 'xgbc': 0.6169627991931004}\n",
      "------\n",
      "For question  VL1r7\n",
      "here are the accuracy scores\n",
      "{'slc': 0.599225641410167, 'svc': 0.5965719144500102, 'knn': 0.549884068247221, 'bagged_lr': 0.5991051597455834, 'ada': 0.5997087328459225, 'bagged_svc': 0.5887298320609353, 'bagged_knn': 0.5818549517236159, 'gbc': 0.6063439602286749, 'rfc': 0.5602599783205802, 'etc': 0.5596569876089521, 'xgbc': 0.5648433046773821}\n",
      "------\n",
      "For question  VL1r10\n",
      "here are the accuracy scores\n",
      "{'slc': 0.7326558453990927, 'svc': 0.7219188543249276, 'knn': 0.68548541735067, 'bagged_lr': 0.7318113089695869, 'ada': 0.7301238376795305, 'bagged_svc': 0.7180583451570376, 'bagged_knn': 0.7199897645184046, 'gbc': 0.7304854282704585, 'rfc': 0.7156460911161698, 'etc': 0.7088897996801229, 'xgbc': 0.7016502712111429}\n",
      "------\n",
      "For question  VL1r11\n",
      "here are the accuracy scores\n",
      "{'slc': 0.7677651488403548, 'svc': 0.7550963744118784, 'knn': 0.7467720741701143, 'bagged_lr': 0.7676445215785936, 'ada': 0.7684884028207998, 'bagged_svc': 0.7522013929281994, 'bagged_knn': 0.765593348538532, 'gbc': 0.7693335216390166, 'rfc': 0.7553391577057671, 'etc': 0.7536504488396997, 'xgbc': 0.7542535123499167}\n",
      "------\n",
      "For question  VL1r12\n",
      "here are the accuracy scores\n",
      "{'slc': 0.9186876161592483, 'svc': 0.919049425145943, 'knn': 0.9106047160381843, 'bagged_lr': 0.9189289434813596, 'ada': 0.9179637797900926, 'bagged_svc': 0.919049425145943, 'bagged_knn': 0.9189289434813596, 'gbc': 0.9168782800314199, 'rfc': 0.9168782800314199, 'etc': 0.9161543708636751, 'xgbc': 0.9113286980045178}\n",
      "------\n",
      "For question  VL1r13\n",
      "here are the accuracy scores\n",
      "{'slc': 0.7820004033041823, 'svc': 0.7813966118080766, 'knn': 0.7468939390078863, 'bagged_lr': 0.7820004033041824, 'ada': 0.7830854662713217, 'bagged_svc': 0.7813966118080766, 'bagged_knn': 0.7797082669349538, 'gbc': 0.7797078301434206, 'rfc': 0.7661965576459266, 'etc': 0.7600433297200968, 'xgbc': 0.7607676756793745}\n",
      "------\n",
      "For question  VL1r14\n",
      "here are the accuracy scores\n",
      "{'slc': 0.8443722686879438, 'svc': 0.8395458678428979, 'knn': 0.8208479870826185, 'bagged_lr': 0.8448548505335772, 'ada': 0.8442515686275938, 'bagged_svc': 0.8395458678428979, 'bagged_knn': 0.8432865505335044, 'gbc': 0.8429242319566879, 'rfc': 0.8356863778552516, 'etc': 0.836289150171113, 'xgbc': 0.8286881767083827}\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for value, scores in all_accuracy.items():\n",
    "    print('For question ', value)\n",
    "    print('here are the accuracy scores')\n",
    "    print(scores)\n",
    "    \n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8251d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  VL1r1\n",
      "Adaboost score was  0.6584647651189929\n",
      "The best performing model was:  gbc\n",
      "with accuracy score  0.6614804466630219\n",
      "-----\n",
      "For  VL1r2\n",
      "Adaboost score was  0.646037682005572\n",
      "The best performing model was:  ada\n",
      "with accuracy score  0.646037682005572\n",
      "-----\n",
      "For  VL1r4\n",
      "Adaboost score was  0.802026567117023\n",
      "The best performing model was:  ada\n",
      "with accuracy score  0.802026567117023\n",
      "-----\n",
      "For  VL1r5\n",
      "Adaboost score was  0.6502603641531013\n",
      "The best performing model was:  gbc\n",
      "with accuracy score  0.6524318732605687\n",
      "-----\n",
      "For  VL1r7\n",
      "Adaboost score was  0.5997087328459225\n",
      "The best performing model was:  gbc\n",
      "with accuracy score  0.6063439602286749\n",
      "-----\n",
      "For  VL1r10\n",
      "Adaboost score was  0.7301238376795305\n",
      "The best performing model was:  slc\n",
      "with accuracy score  0.7326558453990927\n",
      "-----\n",
      "For  VL1r11\n",
      "Adaboost score was  0.7684884028207998\n",
      "The best performing model was:  gbc\n",
      "with accuracy score  0.7693335216390166\n",
      "-----\n",
      "For  VL1r12\n",
      "Adaboost score was  0.9179637797900926\n",
      "The best performing model was:  svc\n",
      "with accuracy score  0.919049425145943\n",
      "-----\n",
      "For  VL1r13\n",
      "Adaboost score was  0.7830854662713217\n",
      "The best performing model was:  ada\n",
      "with accuracy score  0.7830854662713217\n",
      "-----\n",
      "For  VL1r14\n",
      "Adaboost score was  0.8442515686275938\n",
      "The best performing model was:  bagged_lr\n",
      "with accuracy score  0.8448548505335772\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 'S2', 'D4','S12r3','Team6_magnitude', 'Fan_magnitude']\n",
    "for VL in all_accuracy.items():\n",
    "    print('For ', VL[0])\n",
    "\n",
    "   \n",
    "    for i, value in enumerate(VL[1].items()):\n",
    "        if i == 0:\n",
    "            name = value[0]\n",
    "            score = value[1]\n",
    "        if i > 0:\n",
    "            if value[1] > score:\n",
    "                name = value[0]\n",
    "                score = value[1]\n",
    "        if value[0] == 'ada':\n",
    "            print('Adaboost score was ', value[1])\n",
    "    print('The best performing model was: ', name)\n",
    "    print('with accuracy score ', score)\n",
    "    print('-----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0600ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  VL1r1\n",
      "the importance array is\n",
      "[0.14 0.2  0.18 0.08 0.4 ]\n",
      "----\n",
      "For  VL1r2\n",
      "the importance array is\n",
      "[0.24 0.1  0.14 0.16 0.36]\n",
      "----\n",
      "For  VL1r4\n",
      "the importance array is\n",
      "[0.26 0.06 0.16 0.12 0.4 ]\n",
      "----\n",
      "For  VL1r5\n",
      "the importance array is\n",
      "[0.14 0.06 0.3  0.08 0.42]\n",
      "----\n",
      "For  VL1r7\n",
      "the importance array is\n",
      "[0.22 0.06 0.16 0.24 0.32]\n",
      "----\n",
      "For  VL1r10\n",
      "the importance array is\n",
      "[0.28 0.08 0.16 0.08 0.4 ]\n",
      "----\n",
      "For  VL1r11\n",
      "the importance array is\n",
      "[0.18 0.12 0.2  0.22 0.28]\n",
      "----\n",
      "For  VL1r12\n",
      "the importance array is\n",
      "[0.2  0.12 0.14 0.24 0.3 ]\n",
      "----\n",
      "For  VL1r13\n",
      "the importance array is\n",
      "[0.18 0.12 0.16 0.12 0.42]\n",
      "----\n",
      "For  VL1r14\n",
      "the importance array is\n",
      "[0.3  0.06 0.16 0.16 0.32]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# ['S2', 'D4','S12r3','Team6_magnitude', 'Fan_magnitude']\n",
    "for VL, importance in ada_importance.items():\n",
    "    print('For ', VL)\n",
    "    print('the importance array is')\n",
    "    print(importance)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4008af58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  VL1r1\n",
      "the importance array is\n",
      "[0.18227069 0.18109599 0.0940722  0.05824218 0.48431894]\n",
      "----\n",
      "For  VL1r2\n",
      "the importance array is\n",
      "[0.3479413  0.097618   0.0371088  0.09155629 0.4257756 ]\n",
      "----\n",
      "For  VL1r4\n",
      "the importance array is\n",
      "[0.2017354  0.04331803 0.10043807 0.0716396  0.5828689 ]\n",
      "----\n",
      "For  VL1r5\n",
      "the importance array is\n",
      "[0.12317968 0.06912027 0.07294377 0.07379971 0.66095657]\n",
      "----\n",
      "For  VL1r7\n",
      "the importance array is\n",
      "[0.22060782 0.04381869 0.09893242 0.1513415  0.48529957]\n",
      "----\n",
      "For  VL1r10\n",
      "the importance array is\n",
      "[0.3198282  0.03413372 0.04218711 0.05690625 0.54694472]\n",
      "----\n",
      "For  VL1r11\n",
      "the importance array is\n",
      "[0.30204036 0.07978521 0.0959685  0.04317995 0.47902598]\n",
      "----\n",
      "For  VL1r12\n",
      "the importance array is\n",
      "[0.18870323 0.09712926 0.1078432  0.08260891 0.52371539]\n",
      "----\n",
      "For  VL1r13\n",
      "the importance array is\n",
      "[0.16796939 0.07144975 0.04838857 0.13888596 0.57330633]\n",
      "----\n",
      "For  VL1r14\n",
      "the importance array is\n",
      "[0.29896727 0.03361259 0.08344747 0.05929675 0.52467592]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# ['S2', 'D4','S12r3','Team6_magnitude', 'Fan_magnitude']\n",
    "for VL, importance in gbc_importance.items():\n",
    "    print('For ', VL)\n",
    "    print('the importance array is')\n",
    "    print(importance)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59b7002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  VL1r1\n",
      "the importance array is\n",
      "[0.17846404 0.23923336 0.1674664  0.17083648 0.24399978]\n",
      "----\n",
      "For  VL1r2\n",
      "the importance array is\n",
      "[0.22671977 0.18591028 0.16887118 0.17759718 0.2409016 ]\n",
      "----\n",
      "For  VL1r4\n",
      "the importance array is\n",
      "[0.18850158 0.18027602 0.17106912 0.17190938 0.2882439 ]\n",
      "----\n",
      "For  VL1r5\n",
      "the importance array is\n",
      "[0.1835938  0.17577393 0.16572104 0.16918705 0.30572417]\n",
      "----\n",
      "For  VL1r7\n",
      "the importance array is\n",
      "[0.1955036  0.1788336  0.18694891 0.20167771 0.2370362 ]\n",
      "----\n",
      "For  VL1r10\n",
      "the importance array is\n",
      "[0.23477803 0.15210143 0.16049273 0.15889888 0.2937289 ]\n",
      "----\n",
      "For  VL1r11\n",
      "the importance array is\n",
      "[0.23551014 0.18737839 0.1653772  0.149922   0.26181227]\n",
      "----\n",
      "For  VL1r12\n",
      "the importance array is\n",
      "[0.1899572  0.20415819 0.18482003 0.17180638 0.24925816]\n",
      "----\n",
      "For  VL1r13\n",
      "the importance array is\n",
      "[0.18661036 0.18541257 0.16404298 0.19274868 0.2711854 ]\n",
      "----\n",
      "For  VL1r14\n",
      "the importance array is\n",
      "[0.2550368  0.16265246 0.15630457 0.15083262 0.27517363]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# ['S2', 'D4','S12r3','Team6_magnitude', 'Fan_magnitude']\n",
    "for VL, importance in xgbc_importance.items():\n",
    "    print('For ', VL)\n",
    "    print('the importance array is')\n",
    "    print(importance)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75697f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077fef51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
